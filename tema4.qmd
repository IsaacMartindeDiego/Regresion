# Modelos de regresión generalizada {#sec-tema4}

Hasta ahora hemos estuadiado la regresión lineal como una herramienta poderosa para modelar la relación entre una variable dependiente continua y un conjunto de variables independientes. Sin embargo, en muchos contextos del mundo real, las suposiciones de la regresión lineal tradicional no son adecuadas. ¿Qué sucede si la variable dependiente es binaria, como en un diagnóstico médico (enfermo/sano)? ¿O si estás modelando el número de accidentes en una intersección o la cantidad de compras realizadas por un cliente?

Para abordar estos desafíos, se utilizan los llamados **Modelos Lineales Generalizados (GLM)**. Esta clase de modelos amplía la regresión lineal al permitir que la variable dependiente tenga distribuciones diferentes a la normal, como la binomial o la de Poisson. Además, los GLM utilizan funciones de enlace que transforman la relación entre la variable dependiente y los predictores, permitiendo una mayor flexibilidad en el modelado.

Algunos de los modelos más comunes dentro de los GLM son:

  - Regresión Logística: Ideal para variables dependientes binarias (sí/no, éxito/fracaso).
  -  Regresión de Poisson: Utilizada para modelar datos de conteo (número de eventos).
  - Regresión Binomial Negativa: Una extensión de la regresión de Poisson para datos de conteo con sobredispersión.
  -  Modelos de Gamma y Inverso Gaussiano: Utilizados para modelar variables continuas positivas y sesgadas, como tiempos de espera o costos.

En este tema, exploraremos cómo utilizar estos modelos para resolver problemas del mundo real, interpretar sus resultados y evaluar su ajuste.

## Introducción a los GLM

### ¿Qué son los Modelos Lineales Generalizados?

Los **Modelos Lineales Generalizados (GLM)** son una extensión de los modelos de regresión lineal que permiten manejar una mayor variedad de tipos de datos y relaciones entre variables. Mientras que la regresión lineal tradicional asume que la variable dependiente es continua y sigue una distribución normal, los GLM permiten trabajar con variables dependientes que:

  - Son **binarias** (como éxito/fracaso o sí/no).
  - Representan **conteos** de eventos (número de llamadas, accidentes, etc.).
  - Son **continuas positivas** y no siguen una distribución normal (como tiempos o costos).

Los GLM proporcionan una estructura flexible para modelar la relación entre una o más variables independientes y una variable dependiente que sigue alguna distribución de la **familia exponencial** (binomial, Poisson, gamma, entre otras).

### Componentes de un Modelo Lineal Generalizado

Un GLM se define por tres componentes clave:

1. **Componente Aleatorio:**  

   Este componente describe la distribución de la variable dependiente. En la regresión lineal, la variable dependiente sigue una distribución normal. En los GLM, puede seguir otras distribuciones de la **familia exponencial**, como:

   - **Distribución Binomial:** Para variables categóricas binarias (0/1, éxito/fracaso).
   - **Distribución de Poisson:** Para datos de conteo (número de eventos).
   - **Distribución Gamma:** Para variables continuas y positivas (como costos o tiempos).

2. **Componente Sistemático:**  
   Este componente describe cómo las variables independientes se combinan linealmente en el modelo. Se define como:

   $$
   \eta = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p
   $$

   Donde $\eta$ es el **predictor lineal** y $\beta$ representa los coeficientes del modelo.

3. **Función de Enlace:**  
   La función de enlace conecta el componente sistemático con la media de la variable dependiente. Mientras que en la regresión lineal la relación es directa ($Y = \eta $), en los GLM se utiliza una función de enlace $g(\mu)$ para transformar la media $\mu$ y ajustar diferentes tipos de datos.

   $$
   g(\mu) = \eta
   $$

**Ejemplos de funciones de enlace:**

   - **Logística (Logit):** Para la regresión logística, que modela la probabilidad de un evento.
     $$
     g(\mu) = \log\left(\frac{\mu}{1 - \mu}\right)
     $$
   - **Logarítmica:** Para la regresión de Poisson, que modela tasas de eventos.
     $$
     g(\mu) = \log(\mu)
     $$
   - **Identidad:** Para la regresión lineal estándar.
     $$
     g(\mu) = \mu
     $$


::: {.callout-note collapse="true" title="Aplicaciones"}

Los GLM se utilizan en una amplia variedad de disciplinas para resolver problemas del mundo real:

**Regresión Logística (para variables binarias):**  

   - **Medicina:** Predicción de la presencia o ausencia de una enfermedad basada en factores de riesgo.
   - **Marketing:** Determinación de la probabilidad de que un cliente compre un producto.
   - **Finanzas:** Evaluación de la probabilidad de incumplimiento de pago de un préstamo.

**Regresión de Poisson (para datos de conteo):**  

   - **Transporte:** Modelado del número de accidentes en una carretera en un período de tiempo.
   - **Ecología:** Conteo de especies en un área determinada.
   - **Telecomunicaciones:** Número de llamadas recibidas por un centro de atención.

**Regresión Binomial Negativa (para conteos con sobredispersión):**  

   - **Salud Pública:** Modelado del número de visitas al médico o incidentes de una enfermedad en una población.

**Modelos Gamma (para variables continuas positivas):**  
   
   - **Seguros:** Estimación de los costos de reclamos de seguros.
   - **Ingeniería:** Modelado de tiempos de falla en procesos industriales.

:::

### Diferencias clave entre la Regresión Lineal y los GLM

| **Característica**       | **Regresión Lineal**                                | **Modelos Lineales Generalizados (GLM)**               |
|--------------------------|----------------------------------------------------|-------------------------------------------------------|
| **Distribución de la variable dependiente** | Normal                                       | Familia exponencial (binomial, Poisson, gamma, etc.)  |
| **Tipo de variable dependiente**            | Continua                                     | Binaria, de conteo, continua positiva                 |
| **Relación entre las variables**            | Lineal directa                               | Relación transformada mediante una función de enlace  |
| **Función de Enlace**                       | Identidad (\( g(\mu) = \mu \))               | Logit, logarítmica, inversa, etc.                     |

---

Las ventajas principales de los GLM son:

  - **Flexibilidad:** Los GLM permiten modelar diferentes tipos de variables dependientes, lo que amplía significativamente el rango de problemas que se pueden abordar.

  - **Interpretación Coherente:** Aunque se utilizan funciones de enlace, los coeficientes de los GLM pueden interpretarse de manera similar a los modelos lineales, proporcionando información sobre el impacto de cada variable independiente.

  - **Evaluación Estadística Robusta:** Los GLM permiten la realización de pruebas de hipótesis, la construcción de intervalos de confianza y la evaluación de la bondad del ajuste mediante medidas como el **AIC** y el **BIC**.

::: {.callout-tip title="Ejemplo" collapse="true"}
```{r glm1}
# Cargar librería y datos
library(MASS)
data(Pima.tr)  # Datos sobre diabetes en mujeres de origen pima

# Ajustar un modelo de regresión logística
modelo_logistico <- glm(type ~ npreg + glu + bmi, data = Pima.tr, family = binomial)

# Resumen del modelo
summary(modelo_logistico)

# Predicciones de la probabilidad de tener diabetes
predicciones <- predict(modelo_logistico, type = "response")

# Ver primeras predicciones
head(predicciones)
```
:::

---

Los **Modelos Lineales Generalizados** amplían el alcance de la regresión lineal clásica, proporcionando herramientas para modelar una amplia variedad de tipos de datos, desde variables binarias hasta datos de conteo y variables continuas no normales. A través del uso de funciones de enlace y distribuciones flexibles, los GLM permiten resolver problemas complejos del mundo real en campos tan diversos como la medicina, el marketing, la ingeniería y las ciencias sociales.

En las próximas secciones, exploraremos en detalle cómo aplicar estos modelos específicos, como la **regresión logística** y la **regresión de Poisson**, y cómo interpretar sus resultados en diferentes contextos.


## Regresión Logística

La **regresión logística** es una herramienta fundamental para modelar la probabilidad de eventos binarios en una variedad de contextos, desde la medicina hasta la economía y el marketing. La correcta interpretación de los coeficientes mediante **odds ratios**, así como la evaluación del ajuste del modelo mediante curvas **ROC** y matrices de confusión, son esenciales para extraer conclusiones válidas de los datos.

### Fundamentos de la Regresión Logística

La **regresión logística** es una técnica estadística utilizada para modelar la probabilidad de ocurrencia de un evento binario, es decir, cuando la variable dependiente toma solo dos posibles valores (por ejemplo, **éxito/fracaso**, **sí/no**, **enfermo/sano**). A diferencia de la regresión lineal, que modela una relación lineal entre variables, la regresión logística utiliza una **función logística** para asegurar que las predicciones estén en el rango [0,1], lo cual es necesario para interpretar los resultados como probabilidades.

**La función Logística (Sigmoide)**

La función logística transforma cualquier valor real en un valor comprendido entre 0 y 1. La forma matemática de la función logística es:

$$
P(Y = 1 | X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p)}}
$$

Donde:

  - $P(Y = 1 | X)$ es la probabilidad de que el evento ocurra.
  - $\beta_0$ es el intercepto y $\beta_1, \beta_2, \dots, \beta_p$ son los coeficientes asociados a las variables independientes $X_1, X_2, \dots, X_p$.

La **curva sigmoide** que representa esta función tiene forma de "S", lo que refleja que para valores muy pequeños o muy grandes del predictor, la probabilidad se aplana hacia 0 o 1, respectivamente.


**Función de Enlace Logit**

En la regresión logística, la relación entre el predictor lineal y la probabilidad se establece mediante la **función de enlace logit**. El logit de una probabilidad $p$ se define como:

$$
\text{logit}(p) = \log\left(\frac{p}{1 - p}\right)
$$

Esta transformación convierte una probabilidad en una escala que va de $-\infty$ a $+\infty$, lo que permite ajustar un modelo lineal a los datos. El modelo logístico puede expresarse como:

$$
\log\left(\frac{p}{1 - p}\right) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p
$$

### Interpretación de coeficientes y Odds Ratios

Uno de los aspectos más importantes de la regresión logística es la interpretación de los coeficientes. Dado que los coeficientes están en la escala del logit, su interpretación directa no es tan intuitiva como en la regresión lineal. Sin embargo, podemos interpretarlos utilizando **odds** y **odds ratios**.

El **odds** o razón de probabilidades de que ocurra un evento es el cociente entre la probabilidad de que ocurra el evento y la probabilidad de que no ocurra:

$$
\text{odds} = \frac{p}{1 - p}
$$

Por ejemplo, si la probabilidad de éxito es 0.8, el odds sería:

$$
\text{odds} = \frac{0.8}{1 - 0.8} = 4
$$

Esto significa que el evento es **4 veces más probable** que no ocurra.


El **odds ratio (OR)** mide el cambio en los odds cuando una variable independiente aumenta en una unidad. Se calcula como el exponencial del coeficiente de la regresión logística:

$$
\text{OR} = e^{\beta}
$$

**Interpretación de OR:**

  - Si **OR > 1**, el evento es más probable a medida que aumenta la variable independiente.
  - Si **OR < 1**, el evento es menos probable a medida que aumenta la variable independiente.
  - Si **OR = 1**, no hay efecto.


::: {.callout-tip title="Ejemplo" collapse="true"}

Supongamos que ajustamos un modelo de regresión logística para predecir la probabilidad de tener diabetes en función del índice de masa corporal (BMI). El coeficiente asociado a **BMI** es 0.08.

$$
\text{OR} = e^{0.08} \approx 1.083
$$

Esto significa que por cada incremento de 1 unidad en el BMI, la **odds** de tener diabetes aumentan en un **8.3%**.
:::

### Evaluación del modelo Logístico

A diferencia de la regresión lineal, donde se usa el coeficiente de determinación ($R^2$) para evaluar el ajuste, en la regresión logística se utilizan otros métodos para medir la calidad del modelo.


**Matriz de Confusión**

La **matriz de confusión** compara las predicciones del modelo con los valores reales, clasificando las observaciones en:

  - **Verdaderos Positivos (VP):** Predijo positivo y es positivo.
  - **Falsos Positivos (FP):** Predijo positivo pero es negativo.
  - **Verdaderos Negativos (VN):** Predijo negativo y es negativo.
  - **Falsos Negativos (FN):** Predijo negativo pero es positivo.

A partir de esta matriz, se pueden calcular métricas importantes como:

  - **Precisión (Accuracy):** $\frac{VP + VN}{\text{Total}}$
  - **Sensibilidad (Recall o Tasa de Verdaderos Positivos):** $\frac{VP}{VP + FN}$
  - **Especificidad (Tasa de Verdaderos Negativos):** $\frac{VN}{VN + FP}$

::: {.callout-caution title="Aviso"}
Los detalles de la evaluación de un modelo empleando la Matríz de Confusión son ampliamente tratados en la asignatura de Aprendizaje Automático.
:::

**Curva ROC y AUC**

La **Curva ROC (Receiver Operating Characteristic)** muestra la relación entre la **tasa de verdaderos positivos** y la **tasa de falsos positivos** a diferentes umbrales de clasificación.

El **AUC (Área Bajo la Curva ROC)** mide la capacidad del modelo para discriminar entre las clases. Un AUC de $0.5$ indica que el modelo no tiene capacidad predictiva, mientras que un AUC de $1.0$ indica un modelo perfecto.

**Pseudo R² (Nagelkerke, McFadden)**

Aunque el $R^2$ tradicional no se aplica directamente a la regresión logística, existen medidas como el **pseudo $R^2$** que proporcionan una idea de la bondad del ajuste del modelo.

- **McFadden’s $R^2$:**  
  $$
  R^2_{\text{McFadden}} = 1 - \frac{\log L_{\text{modelo}}}{\log L_{\text{modelo nulo}}}
  $$

  Donde $\log L_{\text{modelo}}$ es el log-likelihood del modelo ajustado y $\log L_{\text{modelo nulo}}$ es el log-likelihood de un modelo sin predictores.

::: {.callout-tip title="Ejemplo" collapse="true"}
Vamos a aplicar la regresión logística en R utilizando el conjunto de datos `Pima.tr` del paquete `MASS`, que contiene información sobre mujeres pima y si tienen o no diabetes.

```{r log1}
# Cargar la librería y el conjunto de datos
library(MASS)
data(Pima.tr)

# Ajustar el modelo de regresión logística
modelo_logistico <- glm(type ~ npreg + glu + bmi, data = Pima.tr, family = binomial)

# Resumen del modelo
summary(modelo_logistico)

# Predicciones de probabilidad
predicciones_prob <- predict(modelo_logistico, type = "response")

# Clasificación con un umbral de 0.5
predicciones_clase <- ifelse(predicciones_prob > 0.5, "Yes", "No")

# Crear matriz de confusión
tabla_confusion <- table(Predicted = predicciones_clase, Actual = Pima.tr$type)
print(tabla_confusion)

# Calcular precisión
accuracy <- sum(diag(tabla_confusion)) / sum(tabla_confusion)
print(paste("Precisión:", round(accuracy, 3)))

# Cargar librería para curvas ROC
library(pROC)

# Curva ROC
roc_obj <- roc(Pima.tr$type, predicciones_prob)
plot(roc_obj, main = "Curva ROC para Regresión Logística")

# Calcular AUC
auc_valor <- auc(roc_obj)
print(paste("AUC:", round(auc_valor, 3)))
```
:::

## Regresión de Poisson

La **regresión de Poisson** es una técnica estadística utilizada para modelar **datos de conteo**, es decir, situaciones en las que la variable dependiente representa el número de veces que ocurre un evento en un período de tiempo o espacio específico. Este tipo de modelo es adecuado cuando la variable dependiente toma valores enteros no negativos ($0, 1, 2, \dots$) y sigue una distribución de **Poisson**.

La distribución de Poisson describe la probabilidad de que ocurra un número determinado de eventos en un intervalo fijo, dado que estos eventos ocurren de forma independiente y a una tasa constante.

La **función de probabilidad** de la distribución de Poisson es:

$$
P(Y = y) = \frac{e^{-\lambda} \lambda^y}{y!}
$$

Donde:

- $Y$ es la variable aleatoria que representa el número de eventos.
- $\lambda$ es la **tasa media de ocurrencia** de los eventos (esperanza de $Y$).
- $y$ es el número de eventos observados ($y = 0, 1, 2, \dots$).


### Modelo de Regresión de Poisson

En la **regresión de Poisson**, el objetivo es modelar la relación entre la **tasa de ocurrencia de los eventos** ($\lambda$) y un conjunto de variables predictoras $X_1, X_2, \dots, X_p$.

La **forma funcional** del modelo de Poisson es:

$$
\log(\lambda) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p
$$

Donde:

  - $\log(\lambda)$ es la **función de enlace logarítmica** que asegura que la tasa $\lambda$ sea siempre positiva.
  - $\beta_0, \beta_1, \dots, \beta_p$ son los coeficientes del modelo que describen la influencia de cada predictor sobre la tasa de eventos.

El modelo puede expresarse en términos de la **tasa esperada de eventos** como:

$$
\lambda = e^{\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p}
$$


### Supuestos y Limitaciones de la Regresión de Poisson

tal y como ocurre en el modelo de regresión lineal, para que la regresión de Poisson sea adecuada, se deben cumplir ciertos **supuestos**:

**Independencia de los Eventos:** Los eventos deben ocurrir de manera independiente unos de otros.

**Distribución de Poisson de la Variable Dependiente:** La variable de respuesta debe seguir una distribución de Poisson, donde la **media** y la **varianza** son iguales:

   $$
   E(Y) = Var(Y) = \lambda
   $$

**No Sobredispersión:** Uno de los problemas comunes en los datos de conteo es la **sobredispersión**, que ocurre cuando la varianza de los datos es mayor que la media ($Var(Y) > E(Y)$). La presencia de sobredispersión indica que el modelo de Poisson puede no ser adecuado, y puede ser necesario considerar modelos alternativos como la **regresión binomial negativa**.

**No Exceso de Ceros:** Si hay demasiados ceros en los datos (por ejemplo, en el número de accidentes en diferentes localidades donde muchas tienen cero accidentes), puede ser necesario utilizar modelos de **Poisson inflados en ceros (ZIP)**.

---

#### **3.3. Interpretación de los Resultados**

La interpretación de los coeficientes en la regresión de Poisson difiere de la regresión lineal debido al uso de la función de enlace logarítmica.

##### **Interpretación de los Coeficientes**

- Los coeficientes \( \beta \) representan el **logaritmo de la tasa** de eventos asociados con un cambio en la variable independiente.
  
- Para interpretar en términos de la tasa de ocurrencia, se utiliza el **exponencial de los coeficientes**:

  \[
  e^{\beta_i}
  \]

  Esto representa el **factor de cambio multiplicativo** en la tasa de eventos por cada unidad adicional en la variable \( X_i \).

**Ejemplo:**
- Si \( \beta_1 = 0.5 \), entonces \( e^{0.5} \approx 1.65 \). Esto significa que por cada unidad adicional en \( X_1 \), la tasa de ocurrencia de eventos **aumenta en un 65%**.
- Si \( \beta_1 = -0.3 \), entonces \( e^{-0.3} \approx 0.74 \). Esto indica que por cada unidad adicional en \( X_1 \), la tasa de eventos **disminuye en un 26%**.

---

#### **3.4. Ejemplo Práctico en R: Modelando el Número de Accidentes**

Vamos a utilizar R para ajustar un modelo de regresión de Poisson. Supongamos que tenemos datos sobre el **número de accidentes de tráfico** en diferentes intersecciones de una ciudad, junto con variables como el volumen de tráfico y la visibilidad.

##### **Paso 1: Simulación de Datos**

```r
# Simulación de datos para el número de accidentes
set.seed(123)
n <- 100  # Número de observaciones

# Variables predictoras
trafico <- rnorm(n, mean = 1000, sd = 300)  # Volumen de tráfico en vehículos por día
visibilidad <- rnorm(n, mean = 5, sd = 2)   # Visibilidad en kilómetros

# Generar la tasa de accidentes (lambda) usando un modelo logarítmico
lambda <- exp(0.01 * trafico - 0.2 * visibilidad)

# Generar el número de accidentes como una variable de Poisson
accidentes <- rpois(n, lambda = lambda)

# Crear el data frame
datos_accidentes <- data.frame(accidentes, trafico, visibilidad)
head(datos_accidentes)
```

---

##### **Paso 2: Ajuste del Modelo de Regresión de Poisson**

```r
# Ajustar el modelo de regresión de Poisson
modelo_poisson <- glm(accidentes ~ trafico + visibilidad, data = datos_accidentes, family = poisson)

# Resumen del modelo
summary(modelo_poisson)
```

**Interpretación de los Resultados:**
- El coeficiente asociado a `trafico` indica cómo el volumen de tráfico afecta la tasa de accidentes.
- El coeficiente asociado a `visibilidad` muestra cómo la visibilidad afecta la frecuencia de accidentes.

---

##### **Paso 3: Interpretación de los Coeficientes**

```r
# Exponenciar los coeficientes para interpretar en términos de tasas
exp(coef(modelo_poisson))
```

- Un coeficiente positivo implica que un aumento en la variable está asociado con un **aumento en la tasa de accidentes**.
- Un coeficiente negativo implica que un aumento en la variable está asociado con una **disminución en la tasa de accidentes**.

---

##### **Paso 4: Evaluación del Modelo y Diagnóstico**

1. **Evaluación de Sobredispersión:**

La sobredispersión ocurre cuando la varianza de los datos es mayor que la media, lo que puede invalidar los supuestos de la regresión de Poisson.

```r
# Calcular la relación entre el deviance y los grados de libertad
deviance <- modelo_poisson$deviance
grados_libertad <- modelo_poisson$df.residual
sobredispersion <- deviance / grados_libertad

print(paste("Índice de Sobredispersión:", round(sobredispersion, 2)))
```

- Un valor cercano a 1 sugiere que no hay sobredispersión.
- Un valor significativamente mayor que 1 sugiere la presencia de sobredispersión, y puede ser necesario considerar una **regresión binomial negativa**.

2. **Diagnóstico de Residuos:**

```r
# Gráfico de residuos deviance para evaluar el ajuste
plot(residuals(modelo_poisson, type = "deviance"), main = "Residuos Deviance", ylab = "Residuos", xlab = "Índice")
abline(h = 0, col = "red")
```

---

#### **Ejemplo con Datos Reales en R**

También puedes aplicar la regresión de Poisson a conjuntos de datos reales. Un conjunto de datos clásico en R es **`warpbreaks`**, que contiene el número de roturas de hilo en diferentes condiciones de tensión y longitud del hilo.

```r
# Datos de ejemplo: número de roturas de hilo
data(warpbreaks)

# Ajustar un modelo de Poisson para el número de roturas en función de la tensión
modelo_poisson_real <- glm(breaks ~ wool + tension, data = warpbreaks, family = poisson)

# Resumen del modelo
summary(modelo_poisson_real)

# Interpretación de coeficientes
exp(coef(modelo_poisson_real))
```

---

#### **3.5. Limitaciones y Alternativas**

1. **Sobredispersión:**  
   Si la varianza de los datos es mayor que la media, el modelo de Poisson no será adecuado. En este caso, se recomienda utilizar la **regresión binomial negativa**, que introduce un parámetro adicional para manejar la sobredispersión.

2. **Exceso de Ceros:**  
   Si hay más ceros de los esperados (por ejemplo, muchas intersecciones con cero accidentes), puede ser necesario utilizar modelos de **Poisson inflados en ceros (ZIP)** o **binomial negativa inflada en ceros (ZINB)**.

---

#### **Conclusión**

La **regresión de Poisson** es una herramienta fundamental para modelar **datos de conteo** y comprender cómo las variables predictoras afectan la frecuencia de eventos. Su capacidad para trabajar con tasas de ocurrencia y su flexibilidad en la interpretación de resultados la hacen ideal para una amplia gama de aplicaciones, desde el análisis de accidentes hasta estudios ecológicos y médicos.

Sin embargo, es esencial verificar los supuestos del modelo, especialmente en relación con la **sobredispersión** y el **exceso de ceros**. En la siguiente sección, abordaremos cómo manejar estos desafíos utilizando la **regresión binomial negativa**, una extensión de la regresión de Poisson diseñada para datos con variabilidad excesiva.
